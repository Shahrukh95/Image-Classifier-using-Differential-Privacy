# Image-Classifier-using-Differential-Privacy
Differential Privacy (DP) is a technique for preserving the privacy of individuals in a dataset while allowing meaningful analysis of the data. The idea of the technique is to add random noise to the data in such a way that no inferences can be made about sensitive data. 
